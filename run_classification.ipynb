{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "RtlE7K1NcTK6",
        "mzGT94z6cqmE",
        "k6_hPlqxcy_M"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gstszzw/BERT-SLU/blob/master/run_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w83aw3VcFMe",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Driver\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v3pNeSu3TPx",
        "colab_type": "code",
        "outputId": "a3a43d6e-df32-4f6b-ce50-65d74624c6bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/MyProjects/BERT-SLU\n",
        "\n",
        "!rm -rf /content/*"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/MyProjects/BERT-SLU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cEia2NMuXYQ",
        "colab_type": "code",
        "outputId": "0d64a104-e898-4e4c-dbb7-c0f0a53d391d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 20 14:10:12 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0    33W /  70W |   8527MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtlE7K1NcTK6",
        "colab_type": "text"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:03.192809Z",
          "start_time": "2019-05-10T03:00:01.649485Z"
        },
        "id": "WiZH9TXt2gcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"BERT finetuning runner.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import csv\n",
        "import os\n",
        "from bert import modeling\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxysA12lcaxW",
        "colab_type": "text"
      },
      "source": [
        "### Parameter Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZk77YJ8Fzvl",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "max_seq_length = 50 #@param {type:\"integer\"}\n",
        "train_batch_size = 32 #@param {type:\"integer\"}\n",
        "eval_batch_size = 32 #@param {type:\"integer\"}\n",
        "predict_batch_size = 32 #@param {type:\"integer\"}\n",
        "\n",
        "warmup_proportion = 0.1\n",
        "save_checkpoints_steps = 1000\n",
        "log_step_count_steps = 10\n",
        "save_summary_steps = 1\n",
        "\n",
        "learning_rate = 5e-5 #@param [\"5e-5\", \"3e-5\", \"2e-5\"] {type:\"raw\"}\n",
        "num_train_epochs = 4 #@param {type:\"integer\",min:1, max:10, step:1}\n",
        "do_train = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "do_eval = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "do_predict = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "log_dir = '/content/atis_intent' #@param {type:\"string\"}\n",
        "data_dir = 'data/atis' #@param [\"data/atis\", \"data/snips\"]\n",
        "checkpoints = 'checkpoints/multi_cased_L-12_H-768_A-12' #@param [\"checkpoints/multi_cased_L-12_H-768_A-12\",\"checkpoints/cased_L-12_H-768_A-12\",\"checkpoints/cased_L-24_H-1024_A-16\",\"checkpoints/uncased_L-12_H-768_A-12\",\"checkpoints/uncased_L-24_H-1024_A-16\"]\n",
        "bert_config_file = os.path.join(checkpoints, 'bert_config.json')\n",
        "vocab_file = os.path.join(checkpoints, 'vocab.txt')\n",
        "init_checkpoint = os.path.join(checkpoints, 'bert_model.ckpt')\n",
        "\n",
        "if checkpoints.split('/')[1].startswith('u'):\n",
        "  do_lower_case = True\n",
        "else:\n",
        "  do_lower_case = False    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzGT94z6cqmE",
        "colab_type": "text"
      },
      "source": [
        "### Input Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:03.427032Z",
          "start_time": "2019-05-10T03:00:03.314067Z"
        },
        "id": "OmddfmB_2gcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "          guid: Unique id for the example.\n",
        "          text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "          text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "          label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:03.541764Z",
          "start_time": "2019-05-10T03:00:03.432892Z"
        },
        "id": "ttUP5Rbz2gc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PaddingInputExample(object):\n",
        "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
        "    When running eval/predict on the TPU, we need to pad the number of examples\n",
        "    to be a multiple of the batch size, because the TPU requires a fixed batch\n",
        "    size. The alternative is to drop the last batch, which is bad because it means\n",
        "    the entire output data won't be generated.\n",
        "    We use this class instead of `None` because treating `None` as padding\n",
        "    battches could cause silent errors.\n",
        "    \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:03.650346Z",
          "start_time": "2019-05-10T03:00:03.544107Z"
        },
        "id": "bTq05_Jn2gc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_ids,\n",
        "                 input_mask,\n",
        "                 segment_ids,\n",
        "                 label_id,\n",
        "                 is_real_example=True):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "        self.is_real_example = is_real_example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6_hPlqxcy_M",
        "colab_type": "text"
      },
      "source": [
        "### Data Processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:03.760535Z",
          "start_time": "2019-05-10T03:00:03.652960Z"
        },
        "id": "o00iCDi72gc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataProcessor(object):\n",
        "    \"\"\"Processor for the ATIS data set.\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.train_path = os.path.join(self.data_dir, \"train.tsv\")\n",
        "        self.dev_path = os.path.join(self.data_dir, \"dev.tsv\")\n",
        "        self.test_path = os.path.join(self.data_dir, \"test.tsv\")\n",
        "\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with tf.gfile.Open(input_file, \"r\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                lines.append(line)\n",
        "            return lines\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            text_a = tokenization.convert_to_unicode(line[1])\n",
        "            label = tokenization.convert_to_unicode(line[0])\n",
        "            examples.append(\n",
        "                InputExample(\n",
        "                    guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "        return examples\n",
        "\n",
        "    def get_train_examples(self):\n",
        "        return self._create_examples(self._read_tsv(self.train_path), \"train\")\n",
        "\n",
        "    def get_dev_examples(self):\n",
        "        return self._create_examples(self._read_tsv(self.dev_path), \"dev\")\n",
        "\n",
        "    def get_test_examples(self):\n",
        "        return self._create_examples(self._read_tsv(self.test_path), \"test\")\n",
        "\n",
        "    def get_labels_info(self):\n",
        "        labels = []\n",
        "        label_map = {}\n",
        "        label_map_file = os.path.join(log_dir, \"label_map.txt\")\n",
        "        lines = self._read_tsv(self.train_path) + \\\n",
        "                self._read_tsv(self.dev_path) + \\\n",
        "                self._read_tsv(self.test_path)\n",
        "\n",
        "        for line in lines:\n",
        "            labels += line[0].strip().split()\n",
        "\n",
        "        labels = sorted(set(labels), reverse=True)\n",
        "        num_labels = sorted(set(labels), reverse=True).__len__()\n",
        "\n",
        "        with tf.gfile.GFile(label_map_file, \"w\") as writer:\n",
        "            for (i, label) in enumerate(labels):\n",
        "                label_map[label] = i\n",
        "                writer.write(\"{}:{}\\n\".format(i, label))\n",
        "        return label_map, num_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:03.870000Z",
          "start_time": "2019-05-10T03:00:03.763149Z"
        },
        "id": "OSRm4NKu2gc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_single_example(ex_index, example, label_map, max_seq_length,\n",
        "                           tokenizer):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        return InputFeatures(\n",
        "            input_ids=[0] * max_seq_length,\n",
        "            input_mask=[0] * max_seq_length,\n",
        "            segment_ids=[0] * max_seq_length,\n",
        "            label_id=0,\n",
        "            is_real_example=False)\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    tokens_b = None\n",
        "    if example.text_b:\n",
        "        tokens_b = tokenizer.tokenize(example.text_b)\n",
        "\n",
        "    if tokens_b:\n",
        "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "        # length is less than the specified length.\n",
        "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "    else:\n",
        "        # Account for [CLS] and [SEP] with \"- 2\"\n",
        "        if len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    if tokens_b:\n",
        "        for token in tokens_b:\n",
        "            tokens.append(token)\n",
        "            segment_ids.append(1)\n",
        "        tokens.append(\"[SEP]\")\n",
        "        segment_ids.append(1)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    label_id = label_map[example.label]\n",
        "    if ex_index < 2:\n",
        "        tf.logging.info(\"*** Example ***\")\n",
        "        tf.logging.info(\"guid: %s\" % (example.guid))\n",
        "        tf.logging.info(\"tokens: %s\" % \" \".join(\n",
        "            [tokenization.printable_text(x) for x in tokens]))\n",
        "        tf.logging.info(\n",
        "            \"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "        tf.logging.info(\n",
        "            \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "        tf.logging.info(\n",
        "            \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "        tf.logging.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
        "\n",
        "    feature = InputFeatures(\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids,\n",
        "        label_id=label_id,\n",
        "        is_real_example=True)\n",
        "    return feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:03.968732Z",
          "start_time": "2019-05-10T03:00:03.872481Z"
        },
        "id": "TP92iXJz2gc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def file_based_convert_examples_to_features(examples, label_map, max_seq_length,\n",
        "                                            tokenizer, output_file):\n",
        "    \"\"\"Convert a set of `InputExample`s to a TFRecord file.\"\"\"\n",
        "\n",
        "    writer = tf.python_io.TFRecordWriter(output_file)\n",
        "\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "\n",
        "        feature = convert_single_example(ex_index, example, label_map, max_seq_length, tokenizer)\n",
        "\n",
        "        def create_int_feature(values):\n",
        "            f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
        "            return f\n",
        "\n",
        "        features = collections.OrderedDict()\n",
        "        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
        "        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
        "        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
        "        features[\"label_ids\"] = create_int_feature([feature.label_id])\n",
        "        features[\"is_real_example\"] = create_int_feature([int(feature.is_real_example)])\n",
        "\n",
        "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:04.077032Z",
          "start_time": "2019-05-10T03:00:03.970740Z"
        },
        "id": "vZ33P5RY2gc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
        "                                drop_remainder, batch_size):\n",
        "    \"\"\"Creates an `input_fn` closure to be passed to Estimator.\"\"\"\n",
        "\n",
        "    name_to_features = {\n",
        "        \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
        "        \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    def _decode_record(record, name_to_features):\n",
        "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "        example = tf.parse_single_example(record, name_to_features)\n",
        "\n",
        "        return example\n",
        "\n",
        "    def input_fn():\n",
        "        \"\"\"The actual input function.\"\"\"\n",
        "\n",
        "        # For training, we want a lot of parallel reading and shuffling.\n",
        "        # For eval, we want no shuffling and parallel reading doesn't matter.\n",
        "        d = tf.data.TFRecordDataset(input_file)\n",
        "        if is_training:\n",
        "            d = d.repeat()\n",
        "            d = d.shuffle(buffer_size=100)\n",
        "\n",
        "        d = d.apply(\n",
        "            tf.data.experimental.map_and_batch(\n",
        "                lambda record: _decode_record(record, name_to_features),\n",
        "                batch_size=batch_size,\n",
        "                drop_remainder=drop_remainder))\n",
        "        return d\n",
        "\n",
        "    return input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:04.185478Z",
          "start_time": "2019-05-10T03:00:04.079329Z"
        },
        "id": "vP6nc7xq2gdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3suvDKrc9_o",
        "colab_type": "text"
      },
      "source": [
        "### Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:04.294358Z",
          "start_time": "2019-05-10T03:00:04.187995Z"
        },
        "id": "G7-9pHB02gdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels):\n",
        "    model = modeling.BertModel(\n",
        "        config=bert_config,\n",
        "        is_training=is_training,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        token_type_ids=segment_ids)\n",
        "\n",
        "    # If you want to use the token-level output, use model.get_sequence_output()\n",
        "    # instead.\n",
        "    output_layer = model.get_pooled_output()\n",
        "\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "    output_weights = tf.get_variable(\n",
        "        \"output_weights\", [num_labels, hidden_size],\n",
        "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "    output_bias = tf.get_variable(\n",
        "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "    if is_training:\n",
        "        # I.e., 0.1 dropout\n",
        "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, logits, probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:00:04.404672Z",
          "start_time": "2019-05-10T03:00:04.296622Z"
        },
        "id": "z-RRG_AA2gdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate, num_train_steps, num_warmup_steps):\n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "\n",
        "        tf.logging.info(\"*** Features ***\")\n",
        "        for name in sorted(features.keys()):\n",
        "            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "        is_real_example = None\n",
        "        if \"is_real_example\" in features:\n",
        "            is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "        else:\n",
        "            is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "\n",
        "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "        (total_loss, logits, probabilities) = create_model(\n",
        "            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "            num_labels)\n",
        "\n",
        "        predicted_class = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "\n",
        "        accuracy = tf.metrics.accuracy(labels=label_ids,\n",
        "                                       predictions=predicted_class,\n",
        "                                       weights=is_real_example, name=\"acc_op\")\n",
        "        tf.summary.scalar(\"accuracy\", accuracy[1])\n",
        "\n",
        "        tvars = tf.trainable_variables()\n",
        "        initialized_variable_names = {}\n",
        "        if init_checkpoint:\n",
        "            (assignment_map, initialized_variable_names\n",
        "             ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "\n",
        "            tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "#         tf.logging.info(\"**** Trainable Variables ****\")\n",
        "#         for var in tvars:\n",
        "#             init_string = \"\"\n",
        "#             if var.name in initialized_variable_names:\n",
        "#                 init_string = \", *INIT_FROM_CKPT*\"\n",
        "#             tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape, init_string)\n",
        "\n",
        "        output_spec = None\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "            train_op = optimization.create_optimizer(\n",
        "                total_loss, learning_rate, num_train_steps, num_warmup_steps)\n",
        "\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                loss=total_loss,\n",
        "                train_op=train_op\n",
        "            )\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                loss=total_loss,\n",
        "                eval_metric_ops={\"accuracy\": accuracy}\n",
        "            )\n",
        "        else:\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                predictions={\"predicted_class\": predicted_class,\n",
        "                             \"true_class\": label_ids}\n",
        "            )\n",
        "        return output_spec\n",
        "\n",
        "    return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixu2NqJIdFbT",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:15:45.304338Z",
          "start_time": "2019-05-10T03:00:04.407792Z"
        },
        "scrolled": true,
        "id": "HxnKgYie2gdH",
        "colab_type": "code",
        "outputId": "fc1d22fe-aa99-4662-d944-5183a7d8f4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3219
        }
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "if not do_train and not do_eval and not do_predict:\n",
        "    raise ValueError(\n",
        "        \"At least one of `do_train`, `do_eval` or `do_predict' must be True.\")\n",
        "tf.gfile.MakeDirs(log_dir)\n",
        "processor = DataProcessor(data_dir)\n",
        "label_map, num_labels = processor.get_labels_info()\n",
        "tokenization.validate_case_matches_checkpoint(do_lower_case, init_checkpoint)\n",
        "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
        "\n",
        "if max_seq_length > bert_config.max_position_embeddings:\n",
        "    raise ValueError(\"Cannot use sequence length %d because the BERT model \"\n",
        "                     \"was only trained up to sequence length %d\" %\n",
        "                     (max_seq_length, bert_config.max_position_embeddings))\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "    vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "# distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "run_config = tf.estimator.RunConfig(\n",
        "#     train_distribute=distribution,\n",
        "    model_dir=log_dir,\n",
        "    session_config=config,\n",
        "    save_checkpoints_steps=save_checkpoints_steps,\n",
        "    log_step_count_steps=log_step_count_steps,\n",
        "    save_summary_steps=save_summary_steps)\n",
        "train_examples = None\n",
        "num_train_steps = None\n",
        "num_warmup_steps = None\n",
        "\n",
        "if do_train:\n",
        "    train_examples = processor.get_train_examples()\n",
        "    num_train_steps = int(\n",
        "        len(train_examples) / train_batch_size * num_train_epochs)\n",
        "    num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "    bert_config=bert_config,\n",
        "    num_labels=num_labels,\n",
        "    init_checkpoint=init_checkpoint,\n",
        "    learning_rate=learning_rate,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
        "\n",
        "# Training\n",
        "if do_train:\n",
        "    train_file = os.path.join(log_dir, \"train.tf_record\")\n",
        "    file_based_convert_examples_to_features(\n",
        "        train_examples, label_map, max_seq_length, tokenizer, train_file)\n",
        "    tf.logging.info(\"***** Running training *****\")\n",
        "    tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
        "    tf.logging.info(\"  Batch size = %d\", train_batch_size)\n",
        "    tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "    train_input_fn = file_based_input_fn_builder(\n",
        "        input_file=train_file,\n",
        "        seq_length=max_seq_length,\n",
        "        is_training=True,\n",
        "        drop_remainder=False,\n",
        "        batch_size=train_batch_size)\n",
        "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/content/atis_intent', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': gpu_options {\n",
            "  allow_growth: true\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5930902710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5931770268>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Writing example 0 of 4478\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-0\n",
            "INFO:tensorflow:tokens: [CLS] i want to fly from bal ##timo ##re to dalla ##s round trip [SEP]\n",
            "INFO:tensorflow:input_ids: 101 177 21528 10114 26155 10188 20873 65258 10246 10114 11353 10107 13569 37307 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: atis_flight (id = 11)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-1\n",
            "INFO:tensorflow:tokens: [CLS] round trip fare ##s from bal ##timo ##re to phi ##lade ##lp ##hia less than 1000 dollars round trip fare ##s from den ##ver to phi ##lade ##lp ##hia less than 1000 dollars round trip fare ##s from pit ##ts ##burgh to phi ##lade ##lp ##hia less than [SEP]\n",
            "INFO:tensorflow:input_ids: 101 13569 37307 23252 10107 10188 20873 65258 10246 10114 36500 21805 35451 27919 15306 11084 12186 27953 13569 37307 23252 10107 10188 10140 12563 10114 36500 21805 35451 27919 15306 11084 12186 27953 13569 37307 23252 10107 10188 55277 10806 94202 10114 36500 21805 35451 27919 15306 11084 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: atis_airfare (id = 22)\n",
            "INFO:tensorflow:***** Running training *****\n",
            "INFO:tensorflow:  Num examples = 4478\n",
            "INFO:tensorflow:  Batch size = 32\n",
            "INFO:tensorflow:  Num steps = 559\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 50)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 50)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 50)\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /gdrive/My Drive/MyProjects/BERT-SLU/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /gdrive/My Drive/MyProjects/BERT-SLU/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/atis_intent/model.ckpt.\n",
            "INFO:tensorflow:loss = 3.4136977, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.10324\n",
            "INFO:tensorflow:loss = 2.3592732, step = 10 (9.069 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.30805\n",
            "INFO:tensorflow:loss = 1.536363, step = 20 (4.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.30082\n",
            "INFO:tensorflow:loss = 1.0430152, step = 30 (4.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.28396\n",
            "INFO:tensorflow:loss = 1.0031096, step = 40 (4.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.27533\n",
            "INFO:tensorflow:loss = 0.7736078, step = 50 (4.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.26092\n",
            "INFO:tensorflow:loss = 0.85115343, step = 60 (4.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.24591\n",
            "INFO:tensorflow:loss = 0.99860114, step = 70 (4.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.22544\n",
            "INFO:tensorflow:loss = 0.7945845, step = 80 (4.491 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21306\n",
            "INFO:tensorflow:loss = 0.8621798, step = 90 (4.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.18771\n",
            "INFO:tensorflow:loss = 0.67156863, step = 100 (4.574 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.16732\n",
            "INFO:tensorflow:loss = 0.82230175, step = 110 (4.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.15157\n",
            "INFO:tensorflow:loss = 0.83982337, step = 120 (4.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.13965\n",
            "INFO:tensorflow:loss = 1.0569289, step = 130 (4.676 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.14658\n",
            "INFO:tensorflow:loss = 0.13030566, step = 140 (4.658 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.17259\n",
            "INFO:tensorflow:loss = 0.67100054, step = 150 (4.603 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.19045\n",
            "INFO:tensorflow:loss = 0.56914246, step = 160 (4.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1995\n",
            "INFO:tensorflow:loss = 0.63625467, step = 170 (4.545 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21601\n",
            "INFO:tensorflow:loss = 0.75364655, step = 180 (4.512 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.22843\n",
            "INFO:tensorflow:loss = 0.5618897, step = 190 (4.490 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.22877\n",
            "INFO:tensorflow:loss = 0.41221747, step = 200 (4.485 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.2363\n",
            "INFO:tensorflow:loss = 0.8500031, step = 210 (4.476 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.2391\n",
            "INFO:tensorflow:loss = 0.39106995, step = 220 (4.464 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.23652\n",
            "INFO:tensorflow:loss = 0.37097535, step = 230 (4.472 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.23762\n",
            "INFO:tensorflow:loss = 0.7222599, step = 240 (4.471 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.2326\n",
            "INFO:tensorflow:loss = 0.66979563, step = 250 (4.474 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.22988\n",
            "INFO:tensorflow:loss = 0.48297822, step = 260 (4.485 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.22782\n",
            "INFO:tensorflow:loss = 0.37349606, step = 270 (4.489 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21129\n",
            "INFO:tensorflow:loss = 0.24880122, step = 280 (4.526 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.20987\n",
            "INFO:tensorflow:loss = 0.40069932, step = 290 (4.524 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.2057\n",
            "INFO:tensorflow:loss = 0.70032406, step = 300 (4.535 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.20316\n",
            "INFO:tensorflow:loss = 0.4777789, step = 310 (4.536 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.19967\n",
            "INFO:tensorflow:loss = 0.41725338, step = 320 (4.549 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.19544\n",
            "INFO:tensorflow:loss = 0.73230803, step = 330 (4.554 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.19816\n",
            "INFO:tensorflow:loss = 0.6342087, step = 340 (4.547 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1972\n",
            "INFO:tensorflow:loss = 0.42845836, step = 350 (4.553 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.20113\n",
            "INFO:tensorflow:loss = 0.5046015, step = 360 (4.542 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21173\n",
            "INFO:tensorflow:loss = 0.39562494, step = 370 (4.524 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21434\n",
            "INFO:tensorflow:loss = 1.0141436, step = 380 (4.517 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21376\n",
            "INFO:tensorflow:loss = 0.44418985, step = 390 (4.513 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21624\n",
            "INFO:tensorflow:loss = 0.40685648, step = 400 (4.515 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.22275\n",
            "INFO:tensorflow:loss = 0.75813794, step = 410 (4.497 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.22097\n",
            "INFO:tensorflow:loss = 0.5002061, step = 420 (4.505 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21785\n",
            "INFO:tensorflow:loss = 0.17854515, step = 430 (4.508 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21854\n",
            "INFO:tensorflow:loss = 0.5080533, step = 440 (4.509 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.22295\n",
            "INFO:tensorflow:loss = 0.37381816, step = 450 (4.499 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21858\n",
            "INFO:tensorflow:loss = 0.30033964, step = 460 (4.504 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21939\n",
            "INFO:tensorflow:loss = 0.21917744, step = 470 (4.506 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.2172\n",
            "INFO:tensorflow:loss = 0.47266746, step = 480 (4.510 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21308\n",
            "INFO:tensorflow:loss = 0.25239855, step = 490 (4.522 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21232\n",
            "INFO:tensorflow:loss = 0.29826403, step = 500 (4.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21341\n",
            "INFO:tensorflow:loss = 0.24371834, step = 510 (4.516 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21217\n",
            "INFO:tensorflow:loss = 0.754843, step = 520 (4.523 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21383\n",
            "INFO:tensorflow:loss = 0.18351486, step = 530 (4.517 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.21269\n",
            "INFO:tensorflow:loss = 0.03964082, step = 540 (4.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.20375\n",
            "INFO:tensorflow:loss = 0.45303416, step = 550 (4.537 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 559 into /content/atis_intent/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.4156388.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYRHXA2cdKyk",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:15:45.309668Z",
          "start_time": "2019-05-10T03:00:04.197Z"
        },
        "id": "9m6A-f2V2gdL",
        "colab_type": "code",
        "outputId": "8763c4a2-5836-4255-f497-529f61004798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "if do_eval:\n",
        "    eval_examples = processor.get_dev_examples()\n",
        "    num_actual_eval_examples = len(eval_examples)\n",
        "    eval_file = os.path.join(log_dir, \"eval.tf_record\")\n",
        "    file_based_convert_examples_to_features(\n",
        "        eval_examples, label_map, max_seq_length, tokenizer, eval_file)\n",
        "    tf.logging.info(\"***** Running evaluation *****\")\n",
        "    tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                    len(eval_examples), num_actual_eval_examples,\n",
        "                    len(eval_examples) - num_actual_eval_examples)\n",
        "    tf.logging.info(\"  Batch size = %d\", eval_batch_size)\n",
        "\n",
        "    eval_input_fn = file_based_input_fn_builder(\n",
        "        input_file=eval_file,\n",
        "        seq_length=max_seq_length,\n",
        "        is_training=False,\n",
        "        drop_remainder=False,\n",
        "        batch_size=eval_batch_size)\n",
        "\n",
        "    result = estimator.evaluate(input_fn=eval_input_fn)\n",
        "\n",
        "    output_eval_file = os.path.join(log_dir, \"eval_results.txt\")\n",
        "    with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "        tf.logging.info(\"***** Eval results *****\")\n",
        "        for key in sorted(result.keys()):\n",
        "            tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 500\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-0\n",
            "INFO:tensorflow:tokens: [CLS] i want to fly from bost ##on at 838 am and arrive in den ##ver at 1110 in the morning [SEP]\n",
            "INFO:tensorflow:input_ids: 101 177 21528 10114 26155 10188 29495 10263 10160 82665 10392 10111 27814 10106 10140 12563 10160 106270 10106 10105 28757 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: atis_flight (id = 11)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-1\n",
            "INFO:tensorflow:tokens: [CLS] show me all round trip flights between hou ##ston and las veg ##as [SEP]\n",
            "INFO:tensorflow:input_ids: 101 11897 10911 10435 13569 37307 55650 10948 109601 21884 10111 10285 108193 10403 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: atis_flight (id = 11)\n",
            "INFO:tensorflow:***** Running evaluation *****\n",
            "INFO:tensorflow:  Num examples = 500 (500 actual, 0 padding)\n",
            "INFO:tensorflow:  Batch size = 32\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 50)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 50)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 50)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-20T14:09:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/atis_intent/model.ckpt-559\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-20-14:09:35\n",
            "INFO:tensorflow:Saving dict for global step 559: accuracy = 0.9, global_step = 559, loss = 0.4687708\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 559: /content/atis_intent/model.ckpt-559\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "INFO:tensorflow:  accuracy = 0.9\n",
            "INFO:tensorflow:  global_step = 559\n",
            "INFO:tensorflow:  loss = 0.4687708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKalVYoAdOno",
        "colab_type": "text"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-10T03:15:45.310973Z",
          "start_time": "2019-05-10T03:00:04.199Z"
        },
        "id": "8MCEcX892gdM",
        "colab_type": "code",
        "outputId": "f542dcd0-d7fb-47d4-fe40-cbec41a74066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1146
        }
      },
      "source": [
        "if do_predict:\n",
        "\n",
        "    predict_examples = processor.get_test_examples()\n",
        "    num_actual_predict_examples = len(predict_examples)\n",
        "\n",
        "    predict_file = os.path.join(log_dir, \"predict.tf_record\")\n",
        "    if not tf.gfile.Exists(predict_file):\n",
        "        file_based_convert_examples_to_features(predict_examples, label_map,\n",
        "                                                max_seq_length, tokenizer,\n",
        "                                                predict_file)\n",
        "\n",
        "    tf.logging.info(\"***** Running prediction*****\")\n",
        "    tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                    len(predict_examples), num_actual_predict_examples,\n",
        "                    len(predict_examples) - num_actual_predict_examples)\n",
        "    tf.logging.info(\"  Batch size = %d\", predict_batch_size)\n",
        "\n",
        "    predict_input_fn = file_based_input_fn_builder(\n",
        "        input_file=predict_file,\n",
        "        seq_length=max_seq_length,\n",
        "        is_training=False,\n",
        "        drop_remainder=False,\n",
        "        batch_size=predict_batch_size)\n",
        "\n",
        "    result = estimator.predict(input_fn=predict_input_fn)\n",
        "    label_map_new = {v: k for k, v in label_map.items()}\n",
        "\n",
        "\n",
        "    output_predict_file = os.path.join(log_dir, \"test_results.tsv\")\n",
        "    with tf.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "        writer.write(\"line, true, predict \\n\")\n",
        "        tf.logging.info(\"***** Predict results *****\")\n",
        "\n",
        "        true_classes = []\n",
        "        predicted_classes = []\n",
        "\n",
        "        for i, item in enumerate(result):\n",
        "                true_class = item[\"true_class\"]\n",
        "                predicted_class = item[\"predicted_class\"]\n",
        "\n",
        "                true_classes.append(true_class)\n",
        "                predicted_classes.append(predicted_class)\n",
        "\n",
        "                if predicted_class != true_class:\n",
        "                    output_line = \"{}, {}, {}\\n\".format(i + 1, label_map_new[true_class],\n",
        "                                                        label_map_new[predicted_class])\n",
        "                    writer.write(output_line)\n",
        "    accuracy = metrics.accuracy_score(true_classes, predicted_classes)\n",
        "    classification_report = metrics.classification_report(true_classes, predicted_classes)\n",
        "    tf.logging.info(\"Accuracy: %s\", accuracy)\n",
        "    tf.logging.info(\"Accuracy: %s\", classification_report)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 893\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-0\n",
            "INFO:tensorflow:tokens: [CLS] i would like to find a flight from char ##lotte to las veg ##as that makes a stop in st . lo ##uis [SEP]\n",
            "INFO:tensorflow:input_ids: 101 177 10894 11850 10114 17860 169 23578 10188 101328 92431 10114 10285 108193 10403 10189 20562 169 20517 10106 28780 119 10406 31466 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: atis_flight (id = 11)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-1\n",
            "INFO:tensorflow:tokens: [CLS] on april first i need a ticket from ta ##coma to san jos ##e de ##parti ##ng before 7 am [SEP]\n",
            "INFO:tensorflow:input_ids: 101 10135 11874 10422 177 17367 169 59037 10188 11057 76454 10114 14608 21705 10112 10104 96503 10376 11360 128 10392 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: atis_airfare (id = 22)\n",
            "INFO:tensorflow:***** Running prediction*****\n",
            "INFO:tensorflow:  Num examples = 893 (893 actual, 0 padding)\n",
            "INFO:tensorflow:  Batch size = 32\n",
            "INFO:tensorflow:***** Predict results *****\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 50)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 50)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 50)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/atis_intent/model.ckpt-559\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Accuracy: 0.8824188129899216\n",
            "INFO:tensorflow:Accuracy:               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.00      0.00      0.00         6\n",
            "           4       0.62      0.97      0.76        36\n",
            "           5       0.00      0.00      0.00         7\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         8\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00        12\n",
            "          11       0.94      0.99      0.96       632\n",
            "          12       0.00      0.00      0.00        10\n",
            "          13       0.00      0.00      0.00         2\n",
            "          14       0.00      0.00      0.00         6\n",
            "          16       0.00      0.00      0.00        21\n",
            "          17       0.00      0.00      0.00        18\n",
            "          19       0.86      0.97      0.91        38\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.81      1.00      0.90        48\n",
            "          24       0.28      1.00      0.44         9\n",
            "          25       0.94      1.00      0.97        33\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       893\n",
            "   macro avg       0.22      0.30      0.25       893\n",
            "weighted avg       0.81      0.88      0.84       893\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}